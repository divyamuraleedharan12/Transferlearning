# -*- coding: utf-8 -*-
"""Transfer_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QK0xY-RXsmtTdFgbc6RGlvJNvPNNwRlC

**Import necessary libraries**
"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import random
from tensorflow import keras
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras import  callbacks
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from keras.callbacks import EarlyStopping
from tabulate import tabulate

"""**Load dataset**"""

# Loading the dataset
(X_trainful, y_trainful), (X_test, y_test) = keras.datasets.cifar10.load_data()

#Splitting the trainful set into train and validation set
X_train, X_valid = X_trainful[:-5_000], X_trainful[-5_000:]
y_train, y_valid = y_trainful[:-5_000], y_trainful[-5_000:]

label_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]

"""**Visualization of dataset**"""

# Create a figure with a grid of small image thumbnails by class
num_classes = len(label_names)
num_images_per_class = 10
thumbnail_size = 2.0
font_size = 20
fontweight = 'bold'

plt.figure(figsize=(num_images_per_class * thumbnail_size, num_classes * thumbnail_size))

# Loop through each class
for class_index in range(num_classes):
    class_images = X_train[y_train.flatten() == class_index][:num_images_per_class]

    # Arrange all images for this class in a single row
    row_images = np.concatenate(class_images, axis=1)

    # Plot the row of images
    plt.subplot(num_classes, 1, class_index + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(row_images, aspect='auto', cmap='gray')
    plt.ylabel(label_names[class_index], fontsize=font_size, fontweight=fontweight, rotation=0, labelpad=70)

# Adjust layout and show the plot
plt.tight_layout()
plt.savefig('cifar10_thumbnails.png', dpi=300)
plt.show()

"""**RESNET MODEL**"""

def preprocess_image_input(input_images):
  input_images = input_images.astype('float32')
  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)
  return output_ims

train_X = preprocess_image_input(X_train)
valid_X = preprocess_image_input(X_valid)

"""***Build Model***"""

def define_compile_model(fine_tune_layers=None):
    inputs = tf.keras.layers.Input(shape=(32, 32, 3))

    # Upsample input images to (224, 224, 3)
    resize = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)

    # Load ResNet50 model with pre-trained weights
    resnet = tf.keras.applications.ResNet50(
        input_shape=(224, 224, 3),
        include_top=False,
        weights='imagenet'
    )

    # Freeze or unfreeze layers based on fine_tune_layers argument
    if fine_tune_layers is not None:
        for layer in resnet.layers[:-fine_tune_layers]:
            layer.trainable = False
    else:
        for layer in resnet.layers:
            layer.trainable = False

    # Connect ResNet50 model
    resnet_feature_extractor = resnet(resize)

    # Classifier layers with dropout
    x = tf.keras.layers.GlobalAveragePooling2D()(resnet_feature_extractor)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(256, activation="relu", kernel_regularizer=regularizers.l2(0.01))(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    x = tf.keras.layers.Dense(128, activation="relu", kernel_regularizer=regularizers.l2(0.01))(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    x = tf.keras.layers.Dense(10, activation="softmax", name="classification")(x)

    # Final model
    model = tf.keras.Model(inputs=inputs, outputs=x)

    # Compile the model
    model.compile(optimizer='SGD',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    return model

# Create and compile the model without fine-tuning
model = define_compile_model(fine_tune_layers=90)

# Display the model summary
model.summary()

# Define early stopping callback
early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

"""**Train Model**"""

# Train the model with early stopping
EPOCHS = 5
history_resnet = model.fit(train_X, y_train, epochs=EPOCHS, validation_data=(valid_X, y_valid), batch_size=64, callbacks=[early_stopping])

"""**Evaluate model**"""

test_X = preprocess_image_input(X_test)
test_loss, test_accuracy = model.evaluate(test_X, y_test)
print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Plotting training and validation loss
plt.figure()

plt.plot(history_resnet.history['loss'], label='Training Loss')
plt.plot(history_resnet.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plotting training and validation accuracy

plt.plot(history_resnet.history['accuracy'], label='Training Accuracy')
plt.plot(history_resnet.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

"""**Prediction**"""

# Assuming X_test and y_test are the test data and labels
test_X = preprocess_image_input(X_test)

# Make predictions on the test set
predictions = model.predict(test_X)
predicted_labels = np.argmax(predictions, axis=1)

# Generate a classification report
class_report = classification_report(y_test, predicted_labels, target_names=label_names)

# Print the classification report
print(class_report)

# Assuming X_test and y_test are the test data and labels
test_X = preprocess_image_input(X_test)

# Make predictions on the test set
predictions = model.predict(test_X)
predicted_labels = np.argmax(predictions, axis=1)

# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, predicted_labels)

# Plot confusion matrix using seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Function to plot images with their predicted and true labels
def plot_images(images, true_labels, predicted_labels, label_names):
    plt.figure(figsize=(15, 8))
    for i in range(len(images)):
        plt.subplot(2, 5, i + 1)
        plt.imshow(images[i])
        plt.title(f"True: {label_names[true_labels[i]]}\nPredicted: {label_names[predicted_labels[i]]}")
        plt.axis("off")
    plt.show()

# Select random samples for visualization
num_samples = 10
random_indices = random.sample(range(len(X_test)), num_samples)
sample_images = X_test[random_indices]
sample_true_labels = y_test.flatten()[random_indices]
sample_predictions = predicted_labels[random_indices]

# Visualize predictions
plot_images(sample_images, sample_true_labels, sample_predictions, label_names)

"""**MODEL FROM SCRATCH**

**Prep Data**
"""

# We have to convert it to float32 or float64, otherwise, the type will be mismatched (UFuncTypeError)
X_train = X_train.astype("float32")
X_test = X_test.astype("float32")

# In order to scale (normalize) the values, all of the arrays are divided by 255, which is the maximum value an image can have
X_train = X_train / 255
X_test = X_test / 255

# Assuming you have already defined classes
# One-hot encoding the target class (labels) in order to successfully use categorical_crossentropy as the loss function
y_train = keras.utils.to_categorical(y_train, len(label_names))
y_test = keras.utils.to_categorical(y_test, len(label_names))

"""**Build Model**"""

model = Sequential() # declare the model

# Feature Learning Parts
model.add(Conv2D(32, (3,3), padding="same", activation="relu", input_shape=(32,32,3)))
model.add(BatchNormalization())
model.add(Conv2D(32, (3,3), padding="same", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.4))  # Increase dropout

model.add(Conv2D(64, (3,3), padding="same", activation="relu"))
model.add(BatchNormalization())
model.add(Conv2D(64, (3,3), padding="same", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.5))  # Increase dropout

# Classification Parts
model.add(Flatten())
model.add(Dense(64, activation="relu"))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# Output layer
model.add(Dense(len(label_names), activation="softmax"))

# Model summary
model.summary()

"""**Compile model**"""

model.compile(optimizer="adam", loss=keras.losses.categorical_crossentropy, metrics=["accuracy"])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

"""**Fit model**"""

history_cnn = model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])

"""**Evaluate model**"""

# Evaluate the model on the test set
eval_loss, eval_accuracy = model.evaluate(X_test, y_test)

# Print the accuracy
print("Test Accuracy: {:.2f}%".format(eval_accuracy * 100))

# Plot training & validation loss values
plt.plot(history_cnn.history['loss'], label='Train Loss')
plt.plot(history_cnn.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.savefig('loss_plot.png')
plt.show()

# Plot training & validation accuracy values
plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')
plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('accuracy_plot.png')
plt.show()

"""**Prediction**"""

predictions = model.predict(X_test)
# Get the confusion matrix
conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Print the classification report
print("Classification Report:")
print(classification_report(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1), target_names=label_names))

"""**Comparision of Models**"""

# Assuming you have the training history objects for both models
history_transfer_learning = history_resnet
history_from_scratch = history_cnn

# Function to extract accuracy and training time
def get_metrics(history):
    accuracy = history.history['val_accuracy'][-1] * 100
    training_time = sum(history.epoch) * 5  # Assuming 5 seconds per epoch
    return accuracy, training_time

# Extract accuracy and training time for Transfer Learning and From Scratch
accuracy_transfer_learning, training_time_transfer_learning = get_metrics(history_transfer_learning)
accuracy_from_scratch, training_time_from_scratch = get_metrics(history_from_scratch)

# Data for the bar chart
categories = ['Transfer Learning', 'From Scratch']
accuracy_values = [accuracy_transfer_learning, accuracy_from_scratch]
training_time_values = [training_time_transfer_learning, training_time_from_scratch]

# Define custom colors
accuracy_colors = ['skyblue', 'salmon']
training_time_colors = ['lightblue', 'coral']

# Bar chart for accuracy
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.bar(categories, accuracy_values, color=accuracy_colors, width=0.5, edgecolor='black', linewidth=1.2)
plt.title('Accuracy Comparison')
plt.ylabel('Accuracy (%)')

# Add labels to bars
for i, value in enumerate(accuracy_values):
    plt.text(i, value + 1, f'{value:.2f}%', ha='center', va='bottom', fontweight='bold', color='black')

# Bar chart for training time
plt.subplot(1, 2, 2)
plt.bar(categories, training_time_values, color=training_time_colors, width=0.5, edgecolor='black', linewidth=1.2)
plt.title('Training Time Comparison')
plt.ylabel('Training Time (seconds)')

# Add labels to bars
for i, value in enumerate(training_time_values):
    plt.text(i, value + 5, f'{value}s', ha='center', va='bottom', fontweight='bold', color='black')

plt.tight_layout()
plt.show()